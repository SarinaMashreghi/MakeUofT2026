<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Cupid Bot - Robot Client</title>
    <script src="https://cdn.tailwindcss.com"></script>
  </head>
  <body class="min-h-screen bg-gradient-to-b from-rose-50 via-white to-pink-100 text-rose-900">
    <main class="mx-auto max-w-xl px-4 py-4">
      <section class="mb-4 overflow-hidden rounded-2xl border border-rose-200 bg-white/85 shadow">
        <img
          src="/emoji.png"
          alt="Cupid Bot emoji"
          class="block h-auto w-full object-cover"
          onerror="this.style.display='none';"
        />
      </section>

      <header class="mb-4 rounded-2xl border border-rose-200 bg-white/85 p-4 shadow">
        <h1 class="text-2xl font-bold">Cupid Bot Robot Client</h1>
        <p class="mt-1 text-sm text-rose-700">Use this on the phone mounted on the robot.</p>
        <a href="/" class="mt-3 inline-block rounded-lg bg-rose-100 px-3 py-2 text-sm font-semibold text-rose-800">
          Open Monitor View
        </a>
      </header>

      <section class="mb-4 rounded-2xl border border-rose-200 bg-white/85 p-4 shadow">
        <p class="text-sm font-semibold uppercase tracking-wide text-rose-700">Live Robot State</p>
        <p id="robot-state" class="mt-2 text-lg font-bold">Loading...</p>
      </section>

      <section class="mb-4 rounded-2xl border border-rose-200 bg-white/85 p-4 shadow">
        <p class="text-sm font-semibold uppercase tracking-wide text-rose-700">Speaker Output</p>
        <p id="latest-text" class="mt-2 text-sm text-rose-800">Waiting for speech...</p>
        <audio id="player" class="mt-3 w-full" controls autoplay></audio>
      </section>

      <section class="rounded-2xl border border-rose-200 bg-white/85 p-4 shadow">
        <p class="text-sm font-semibold uppercase tracking-wide text-rose-700">Microphone</p>
        <p id="mic-status" class="mt-2 text-sm text-rose-700">Waiting for user turn...</p>
      </section>
    </main>

    <script>
      const robotStateEl = document.getElementById("robot-state");
      const latestTextEl = document.getElementById("latest-text");
      const playerEl = document.getElementById("player");
      const micStatusEl = document.getElementById("mic-status");

      let lastAudioId = 0;
      let robotState = "idle";
      let mediaRecorder = null;
      let micStream = null;
      let isRecording = false;
      let isProcessing = false;
      let currentMood = "happy";
      let conversationApiAvailable = true;
      let robotAudioPlaying = false;

      function formatRobotState(state, direction) {
        if (state === "conversation_ongoing") return "Conversation ongoing (robot paused)";
        if (state === "awaiting_user_reply") return "Awaiting user reply (invite is repeating)";
        if (state === "moving_towards_target") {
          return `Moving toward target (${direction || "forward"})`;
        }
        if (state === "target_reached") return "Target reached";
        return "No target in range, searching";
      }

      async function pollStatus() {
        try {
          const res = await fetch("/status", { cache: "no-store" });
          const data = await res.json();
          robotState = data.robot_state || "idle";
          robotStateEl.textContent = formatRobotState(data.robot_state, data.robot_direction);
          currentMood = data.conversation_mood || "happy";
          conversationApiAvailable = data.conversation_api_available !== false;
          if (!conversationApiAvailable) {
            const apiErr = data.conversation_api_error || "unknown import/route error";
            micStatusEl.textContent = `Conversation API unavailable on server: ${apiErr}`;
          }
          tickAutoListen();
        } catch {
          robotStateEl.textContent = "Status unavailable";
        }
      }

      async function pollLatestAudio() {
        try {
          const res = await fetch("/api/audio/latest", { cache: "no-store" });
          const data = await res.json();
          if (!data.audio_url || data.id === lastAudioId) return;

          lastAudioId = data.id;
          latestTextEl.textContent = data.text || "New audio";
          const src = `${data.audio_url}?v=${data.id}`;
          playerEl.src = src;
          try {
            await playerEl.play();
            robotAudioPlaying = true;
          } catch {
            // Autoplay can be blocked until user interacts on some devices.
            robotAudioPlaying = false;
          }
        } catch {
          // ignore transient errors
        }
      }

      async function fetchJsonWithTimeout(url, options, timeoutMs) {
        return await Promise.race([
          fetch(url, options),
          new Promise((_, reject) => setTimeout(() => reject(new Error("timeout")), timeoutMs)),
        ]);
      }

      function shouldAutoListen(state) {
        return state === "awaiting_user_reply" && !robotAudioPlaying;
      }

      async function ensureMicStream() {
        if (micStream) return micStream;
        micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        return micStream;
      }

      async function captureSingleUtterance() {
        if (isRecording || isProcessing) return;
        try {
          const stream = await ensureMicStream();
          const chunks = [];
          mediaRecorder = new MediaRecorder(stream);
          mediaRecorder.ondataavailable = (e) => {
            if (e.data && e.data.size > 0) chunks.push(e.data);
          };
          mediaRecorder.onstop = async () => {
            isRecording = false;
            const blob = new Blob(chunks, { type: "audio/webm" });
            if (!blob.size) {
              micStatusEl.textContent = "No speech detected, retrying...";
              return;
            }
            const fd = new FormData();
            fd.append("audio", blob, "robot_mic.webm");
            fd.append("mood", currentMood);
            isProcessing = true;
            if (!conversationApiAvailable) {
              micStatusEl.textContent = "Conversation API unavailable on server";
              isProcessing = false;
              return;
            }
            micStatusEl.textContent = "Processing...";
            console.log("[robot] sending /api/process", { mood: currentMood, bytes: blob.size });

            try {
              micStatusEl.textContent = "Sending request to /api/process...";
              const resp = await fetchJsonWithTimeout("/api/process", {
                method: "POST",
                body: fd,
              }, 45000);
              const data = await resp.json();
              console.log("[robot] /api/process response", { ok: resp.ok, data });
              if (!resp.ok) {
                micStatusEl.textContent = data.error || "Processing failed";
                return;
              }
              micStatusEl.textContent = "Response generated";
              if (data.text) latestTextEl.textContent = data.text;
              if (data.audio_url) {
                playerEl.src = `${data.audio_url}?v=${Date.now()}`;
                try {
                  await playerEl.play();
                } catch {
                  // autoplay may still be blocked
                }
              }
            } catch {
              console.log("[robot] /api/process failed or timed out");
              micStatusEl.textContent = "Processing timed out or /api/process unreachable";
            } finally {
              isProcessing = false;
              if (shouldAutoListen(robotState)) {
                setTimeout(tickAutoListen, 400);
              }
            }
          };

          mediaRecorder.start();
          isRecording = true;
          micStatusEl.textContent = "Listening...";
          setTimeout(() => {
            if (mediaRecorder && mediaRecorder.state !== "inactive") {
              mediaRecorder.stop();
            }
          }, 4500);
        } catch {
          micStatusEl.textContent = "Microphone permission denied";
        }
      }

      function tickAutoListen() {
        if (robotState === "awaiting_user_reply" && robotAudioPlaying) {
          micStatusEl.textContent = "Waiting for robot message to finish...";
          return;
        }
        if (!shouldAutoListen(robotState)) {
          if (!isRecording && !isProcessing) {
            micStatusEl.textContent = "Waiting for user turn...";
          }
          return;
        }
        if (!isRecording && !isProcessing) {
          captureSingleUtterance();
        }
      }

      setInterval(pollStatus, 1200);
      setInterval(pollLatestAudio, 800);
      setInterval(tickAutoListen, 1000);
      playerEl.addEventListener("play", () => {
        robotAudioPlaying = true;
      });
      playerEl.addEventListener("ended", () => {
        robotAudioPlaying = false;
        tickAutoListen();
      });
      playerEl.addEventListener("pause", () => {
        if (playerEl.ended || playerEl.currentTime >= (playerEl.duration || 0)) {
          robotAudioPlaying = false;
          tickAutoListen();
        }
      });
      playerEl.addEventListener("error", () => {
        robotAudioPlaying = false;
      });
      pollStatus();
      pollLatestAudio();
    </script>
  </body>
</html>
